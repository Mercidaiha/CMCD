{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv(\"../../../data/ifly/train.csv\")\n",
    "valid_data = pd.read_csv(\"../../../data/ifly/valid.csv\")\n",
    "test_data = pd.read_csv(\"../../../data/ifly/test.csv\")\n",
    "\n",
    "train_data = train_data.rename(columns={'user_id': 'user_id'})\n",
    "train_data = train_data.rename(columns={'question_id': 'item_id'})\n",
    "train_data = train_data.rename(columns={'correct': 'score'})\n",
    "\n",
    "valid_data = valid_data.rename(columns={'user_id': 'user_id'})\n",
    "valid_data = valid_data.rename(columns={'question_id': 'item_id'})\n",
    "valid_data = valid_data.rename(columns={'correct': 'score'})\n",
    "\n",
    "test_data = test_data.rename(columns={'user_id': 'user_id'})\n",
    "test_data = test_data.rename(columns={'question_id': 'item_id'})\n",
    "test_data = test_data.rename(columns={'correct': 'score'})\n",
    "\n",
    "sample_size = 6\n",
    "\n",
    "def fake_train_data(train_data, valid_data, test_data, s):\n",
    "    all_data = pd.concat([train_data, valid_data, test_data], axis=0)\n",
    "    existing_all_users = all_data['user_id'].unique()\n",
    "    existing_train_users = train_data['user_id'].unique()\n",
    "    new_train_data = []\n",
    "    for train_user in existing_train_users:\n",
    "        user_data = train_data[train_data['user_id'] == train_user]\n",
    "\n",
    "        num_rows = len(user_data)\n",
    "        if num_rows < s:\n",
    "            random_rows = list(range(num_rows))\n",
    "            s = num_rows\n",
    "        else:\n",
    "            random_rows = random.sample(range(num_rows), s)\n",
    "\n",
    "        fake_user_ids = []\n",
    "        for _ in range(s):\n",
    "            fake_user_id = max(existing_all_users) + 1\n",
    "            while fake_user_id in existing_all_users:\n",
    "                fake_user_id += 1\n",
    "            existing_all_users = np.append(existing_all_users, fake_user_id)\n",
    "            fake_user_ids.append(fake_user_id)\n",
    "\n",
    "        pos = [(user_data.iloc[i]['score'] - 0.5) * 2 for i in random_rows]\n",
    "        row_count = 0\n",
    "        for index, row in user_data.iterrows():\n",
    "            user_id = row['user_id']\n",
    "            item_id = row['item_id']\n",
    "            score = row['score']\n",
    "\n",
    "            data_point = {\n",
    "                'user_id': user_id,\n",
    "                'item_id': item_id,\n",
    "                'score': score,\n",
    "                'user_id_pair': fake_user_ids,\n",
    "                'pos': pos,\n",
    "                'fake': 0\n",
    "            }\n",
    "            new_train_data.append(data_point)\n",
    "\n",
    "            for i in range(s):   \n",
    "                if row_count == random_rows[i]:\n",
    "                    fake_score = 1 - score\n",
    "                    fake_data_point = {\n",
    "                        'user_id': fake_user_ids[i],\n",
    "                        'item_id': item_id,\n",
    "                        'score': fake_score,\n",
    "                        'user_id_pair': [user_id] * s,\n",
    "                        'pos': [- pos[i]] * s,\n",
    "                        'fake': 1\n",
    "                    }\n",
    "                    new_train_data.append(fake_data_point)\n",
    "                else:\n",
    "                    fake_data_point = {\n",
    "                        'user_id': fake_user_ids[i],\n",
    "                        'item_id': item_id,\n",
    "                        'score': score,\n",
    "                        'user_id_pair': [user_id] * s,\n",
    "                        'pos': [- pos[i]] * s,\n",
    "                        'fake': 1\n",
    "                    }\n",
    "                    new_train_data.append(fake_data_point)\n",
    "            row_count += 1\n",
    "\n",
    "    new_train_data_df = pd.DataFrame(new_train_data)\n",
    "    shuffled_data = new_train_data_df.sample(frac=1).reset_index(drop=True)\n",
    "    return shuffled_data, max(existing_all_users)\n",
    "\n",
    "train_data, user_num = fake_train_data(train_data, valid_data, test_data, sample_size)\n",
    "train_data.to_csv(\"../../../data/ifly/\" + str(sample_size) + \"_fake_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/zhengz/anaconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "# 2021/3/23 @ tongshiwei\n",
    "import sys\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "import logging\n",
    "from EduCDM import CIRT\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 256\n",
    "sample_size = 2\n",
    "\n",
    "train_data = pd.read_csv(\"../../../data/ifly/\" + str(sample_size) + \"_fake_train.csv\")\n",
    "valid_data = pd.read_csv(\"../../../data/ifly/valid.csv\")\n",
    "test_data = pd.read_csv(\"../../../data/ifly/test.csv\")\n",
    "\n",
    "valid_data = valid_data.rename(columns={'user_id': 'user_id'})\n",
    "valid_data = valid_data.rename(columns={'question_id': 'item_id'})\n",
    "valid_data = valid_data.rename(columns={'correct': 'score'})\n",
    "\n",
    "test_data = test_data.rename(columns={'user_id': 'user_id'})\n",
    "test_data = test_data.rename(columns={'question_id': 'item_id'})\n",
    "test_data = test_data.rename(columns={'correct': 'score'})\n",
    "\n",
    "\n",
    "\n",
    "def transform(x, y, z, batch_size, **params):\n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(x, dtype=torch.int64),\n",
    "        torch.tensor(y, dtype=torch.int64),\n",
    "        torch.tensor(z, dtype=torch.float32)\n",
    "    )\n",
    "    return DataLoader(dataset, batch_size=batch_size, **params)\n",
    "\n",
    "def transform_train_data(x, y, z, f, p, batch_size, **params):\n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(x, dtype=torch.int64),\n",
    "        torch.tensor(y, dtype=torch.int64),\n",
    "        torch.tensor(z, dtype=torch.float32),\n",
    "        torch.tensor(f, dtype=torch.int64),\n",
    "        torch.tensor(p, dtype=torch.float32)\n",
    "    )\n",
    "    return DataLoader(dataset, batch_size=batch_size, **params)\n",
    "\n",
    "\n",
    "\n",
    "valid, test = [\n",
    "    transform(data[\"user_id\"], data[\"item_id\"], data[\"score\"], batch_size)\n",
    "    for data in [valid_data, test_data]\n",
    "]\n",
    "\n",
    "\n",
    "user_id_pair = []\n",
    "pos = []\n",
    "for i, s in train_data.iterrows():\n",
    "    codes1 = eval(s['user_id_pair'])\n",
    "    codes2 = eval(s['pos'])\n",
    "    user_id_pair.append(codes1)\n",
    "    pos.append(codes2)\n",
    "    \n",
    "train = transform_train_data(train_data[\"user_id\"], train_data[\"item_id\"], train_data[\"score\"], user_id_pair, pos, batch_size)\n",
    "# print(train_data[\"pos\"])\n",
    "# print(max(train_data['user_id'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3153/3153 [00:37<00:00, 84.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] LogisticLoss: 0.811351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 262.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] rmse: 0.497489, mae: 0.419493, auc: 0.624473, accuracy: 0.624302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3153/3153 [00:37<00:00, 85.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] LogisticLoss: 0.690910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 241.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] rmse: 0.468187, mae: 0.395816, auc: 0.708220, accuracy: 0.661395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3153/3153 [00:38<00:00, 81.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] LogisticLoss: 0.619208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 280.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] rmse: 0.448468, mae: 0.378244, auc: 0.752354, accuracy: 0.692508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3153/3153 [00:35<00:00, 89.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] LogisticLoss: 0.573452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 146.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] rmse: 0.434910, mae: 0.364805, auc: 0.778102, accuracy: 0.712573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3153/3153 [00:34<00:00, 91.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] LogisticLoss: 0.542294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 288.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] rmse: 0.425387, mae: 0.354312, auc: 0.794488, accuracy: 0.726839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3153/3153 [00:36<00:00, 85.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] LogisticLoss: 0.520243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 211.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] rmse: 0.418467, mae: 0.345951, auc: 0.805692, accuracy: 0.737706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3153/3153 [00:37<00:00, 83.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] LogisticLoss: 0.503826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 199.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] rmse: 0.413307, mae: 0.339097, auc: 0.813745, accuracy: 0.744536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3153/3153 [00:35<00:00, 88.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] LogisticLoss: 0.491127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 307.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] rmse: 0.409398, mae: 0.333380, auc: 0.819725, accuracy: 0.750212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3153/3153 [00:37<00:00, 83.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] LogisticLoss: 0.481004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 290.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] rmse: 0.406387, mae: 0.328533, auc: 0.824268, accuracy: 0.754341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3153/3153 [00:36<00:00, 86.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] LogisticLoss: 0.472728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 216.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] rmse: 0.404041, mae: 0.324361, auc: 0.827791, accuracy: 0.758347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 3153/3153 [00:44<00:00, 70.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] LogisticLoss: 0.465829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 137.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] rmse: 0.402202, mae: 0.320733, auc: 0.830547, accuracy: 0.761262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 3153/3153 [00:46<00:00, 67.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] LogisticLoss: 0.460000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 151.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] rmse: 0.400757, mae: 0.317553, auc: 0.832709, accuracy: 0.763204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 3153/3153 [00:47<00:00, 65.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] LogisticLoss: 0.455025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 150.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] rmse: 0.399623, mae: 0.314753, auc: 0.834421, accuracy: 0.764631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 3153/3153 [00:44<00:00, 70.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] LogisticLoss: 0.450744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 157.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] rmse: 0.398735, mae: 0.312277, auc: 0.835782, accuracy: 0.765875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 3153/3153 [00:50<00:00, 62.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] LogisticLoss: 0.447032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 136.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] rmse: 0.398042, mae: 0.310081, auc: 0.836861, accuracy: 0.767120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 3153/3153 [00:48<00:00, 65.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] LogisticLoss: 0.443789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 152.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] rmse: 0.397503, mae: 0.308126, auc: 0.837714, accuracy: 0.767848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 3153/3153 [00:53<00:00, 59.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] LogisticLoss: 0.440934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 153.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] rmse: 0.397086, mae: 0.306381, auc: 0.838387, accuracy: 0.768547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 3153/3153 [00:53<00:00, 59.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] LogisticLoss: 0.438403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 170.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] rmse: 0.396767, mae: 0.304817, auc: 0.838925, accuracy: 0.769123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 3153/3153 [00:47<00:00, 65.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] LogisticLoss: 0.436146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 183.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] rmse: 0.396526, mae: 0.303412, auc: 0.839351, accuracy: 0.769822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 3153/3153 [00:46<00:00, 68.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] LogisticLoss: 0.434121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 129/129 [00:00<00:00, 183.70it/s]\n",
      "INFO:root:save parameters to cirt_ifly.params\n",
      "INFO:root:load parameters from cirt_ifly.params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] rmse: 0.396348, mae: 0.302146, auc: 0.839679, accuracy: 0.770459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 322/322 [00:01<00:00, 194.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.394825, mae: 0.300433, auc: 0.842306, accuracy: 0.772410\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "import logging\n",
    "from EduCDM import CIRT\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "user_num = max(train_data['user_id'].unique())\n",
    "# print(user_num)\n",
    "cdm = CIRT(user_num + 1, 12130, a_range=1, zeta=0.3)\n",
    "\n",
    "cdm.train(train, valid, epoch=20, device=\"cuda\")\n",
    "cdm.save(\"cirt_ifly.params\")\n",
    "\n",
    "cdm.load(\"cirt_ifly.params\")\n",
    "rmse, mae, auc, accuracy = cdm.eval(test)\n",
    "print(\"rmse: %.6f, mae: %.6f, auc: %.6f, accuracy: %.6f\" % (rmse, mae, auc, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7fa0001a5750>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fa0001a7850>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "from EduCDM import CIRT\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 256\n",
    "def transform(x, y, z, batch_size, **params):\n",
    "    x = x.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    z = z.to_numpy()\n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(x, dtype=torch.int64),\n",
    "        torch.tensor(y, dtype=torch.int64),\n",
    "        torch.tensor(z, dtype=torch.float32)\n",
    "    )\n",
    "    return DataLoader(dataset, batch_size=batch_size, **params)\n",
    "\n",
    "\n",
    "test_data = pd.read_csv('../../../data/ifly/test.csv')\n",
    "user_id_mapping = pd.read_csv('../../../data/ifly/user_id_mapping.csv')\n",
    "test_data = test_data.merge(user_id_mapping, on='user_id', how='inner')\n",
    "\n",
    "sorted_select_users = pd.read_csv('../../../data/ifly/sorted_select_users.csv')\n",
    "sorted_select_users = sorted_select_users.drop(\"user_id_mapping\", axis=1)\n",
    "sorted_select_users = sorted_select_users.rename(columns={'user_id': 'user_id_mapping'})\n",
    "test_data = test_data.merge(sorted_select_users, on='user_id_mapping', how='inner')\n",
    "\n",
    "group_information = pd.read_csv('../../../data/ifly/group_information.csv')\n",
    "group_information = group_information.drop(\"user_id\", axis=1)\n",
    "group_information = group_information.drop(\"count\", axis=1)\n",
    "test_data = test_data.merge(group_information, on='province_id', how='inner')\n",
    "\n",
    "\n",
    "test1_data = test_data[test_data['avg'] < 80]\n",
    "test2_data = test_data[test_data['avg'] >= 80]\n",
    "\n",
    "test1, test2 = [\n",
    "    transform(data[\"user_id\"], data[\"question_id\"], data[\"correct\"], batch_size)\n",
    "    for data in [test1_data, test2_data]\n",
    "]\n",
    "test1, test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load parameters from cirt_ifly.params\n",
      "evaluating: 100%|██████████| 143/143 [00:01<00:00, 99.72it/s] \n",
      "INFO:root:load parameters from cirt_ifly.params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.408366, mae: 0.316202, auc: 0.833092, accuracy: 0.753694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 173/173 [00:01<00:00, 122.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.382831, mae: 0.287054, auc: 0.842472, accuracy: 0.788208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cdm.load(\"cirt_ifly.params\")\n",
    "rmse, mae, auc, accuracy = cdm.eval(test1)\n",
    "print(\"rmse: %.6f, mae: %.6f, auc: %.6f, accuracy: %.6f\" % (rmse, mae, auc, accuracy))\n",
    "\n",
    "cdm.load(\"cirt_ifly.params\")\n",
    "rmse, mae, auc, accuracy = cdm.eval(test2)\n",
    "print(\"rmse: %.6f, mae: %.6f, auc: %.6f, accuracy: %.6f\" % (rmse, mae, auc, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
